{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"uva_seal.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLlib Regression\n",
    "\n",
    "### University of Virginia\n",
    "### DS 5110: Big Data Systems\n",
    "### Last Updated: March 25, 2021\n",
    "\n",
    "---  \n",
    "\n",
    "\n",
    "### SOURCES\n",
    "Learning Spark, Chapter 11: Machine Learning with MLlib\n",
    "\n",
    "*Details on regularization equation*  \n",
    "https://spark.apache.org/docs/1.5.2/ml-linear-methods.html\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression\n",
    "\n",
    "\n",
    "### OBJECTIVES\n",
    "- Introduction to major regression models in MLlib using the DataFrame API\n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- Linear regression\n",
    "- VectorAssembler\n",
    "- RegressionEvaluator\n",
    "\n",
    "---\n",
    "\n",
    "**Introduction to Regression**\n",
    "\n",
    "Regression is another common form of supervised learning\n",
    "The response variable in a regression problem is quantitative or continuous  \n",
    "\n",
    "Earlier, we discussed the classification problem where the response variable is discrete\n",
    "\n",
    "Several of the models we discussed for classification also have regression counterparts, including:\n",
    "\n",
    "- Support vector machines  \n",
    "- Tree-based methods like random forests and gradient-boosted trees  \n",
    "\n",
    "To implement the regression counterpart, the same package is loaded but a different method is called.\n",
    "\n",
    "**Linear Regression**\n",
    "\n",
    "Linear regression is the most fundamental model used in regression.\n",
    "\n",
    "Model assumes a linear relationship between a set of explanatory variables $X$ (aka features, factors, predictors, independent variables) and a scalar response variable $Y$.\n",
    "\n",
    "Linear regression models are most often fit using the *ordinary least squares* (*OLS*) approach.  \n",
    "\n",
    "More recently and especially in machine learning, an additional regularization term is added to the loss function. Examples include:\n",
    "\n",
    "- ridge regression ($L^2$-norm penalty)\n",
    "- lasso ($L^1$-norm penalty)\n",
    "- elastic net is a blend of ridge and lasso regression\n",
    "\n",
    "#### Linear Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"mllib_classifier\").getOrCreate()\n",
    "\n",
    "# Load training data\n",
    "filename = \"sample_housing_data.csv\"\n",
    "training = spark.read.csv(filename,  inferSchema=True, header = True)\n",
    "training.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DataFrame API version of MLlib, features need to be assembled into a feature column for the ML \n",
    "Model\n",
    "\n",
    "`VectorAssembler` will handle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# inputCols take a list of column names\n",
    "# outputCol is arbitrary name of new column; generally called features\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"median_income\", \"total_rooms\"],\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "tr = assembler.transform(training)\n",
    "tr.select(\"*\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set up the Linear Regression Model and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol='features',         # feature vector name\n",
    "                      labelCol='median_house_value',  # target variable name\n",
    "                      maxIter=10,\n",
    "                      regParam=0.3, \n",
    "                      elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(tr)\n",
    "\n",
    "# Print the weights and intercept for linear regression\n",
    "print(\"Weights: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's measure the model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# compute predictions. this will append column \"prediction\" to dataframe\n",
    "lrPred = lrModel.transform(tr)\n",
    "lrPred.show(1)\n",
    "\n",
    "ev = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"median_house_value\")\n",
    "\n",
    "print('-'*20)\n",
    "print(\"METRICS\")\n",
    "print(\"Mean Squared Error:\", ev.evaluate(lrPred, {ev.metricName: \"mse\"}))\n",
    "print(\"R Squared:\", ev.evaluate(lrPred, {ev.metricName:'r2'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "Notice we extracted a metric like MSE by: \n",
    "1. passing to the evaluator a dataframe with labels and predictions\n",
    "2. going to the Regression Evaluator dictionary with the desired key: \"mse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ev.evaluate(lrPred, {ev.metricName: \"mse\"})```\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization Parameters\n",
    "\n",
    "You might have noticed the parameters `regParam` and `elasticNetParam` in the function call above.  \n",
    "You can read about them [here](https://spark.apache.org/docs/1.5.2/ml-linear-methods.html).  \n",
    "\n",
    "The `elasticNetParam` parameter controls the relative blending of Lasso and Ridge regression.  \n",
    "These regularization terms often help a model better generalize to new data by reducing overfitting.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Regression Models using the DataFrame API\n",
    "\n",
    "PySpark supports several regression models including:  \n",
    "- Generalized linear regression\n",
    "- Decision tree regression\n",
    "- Random forest regression\n",
    "- Gradient-boosted tree regression\n",
    "\n",
    "For more details, including code examples, please see [here](https://spark.apache.org/docs/latest/ml-classification-regression.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRY FOR YOURSELF (UNGRADED EXERCISES)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Copy the Linear Regression example from above, and modify in the cells below to fit and evaluate these two models:  \n",
    "\n",
    "i. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Think of at least one real-world example of when you would need to implement each of the following tasks:  \n",
    "- regression\n",
    "- binary classification\n",
    "- multiclass classification\n",
    "- multilabel classification\n",
    "\n",
    "If you are not sure about the difference between multiclass and multilabel, here is one resource:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/multiclass.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
