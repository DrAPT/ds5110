{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University of Virginia\n",
    "### DS 5110: Big Data Systems\n",
    "### K-Means Cluster Analysis of Fidelity Fund Returns \n",
    "### Last updated: March 22, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this assignment, you will conduct a k-means cluster analysis on a set of Fidelity mutual funds.  \n",
    "This helps to group similar funds based on their performance (as opposed to their description, which is typical).  \n",
    "The outline below will walk you through the required steps.  \n",
    "\n",
    "This assignment is worth a total of **10 POINTS.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Details \n",
    "\n",
    "The file *fido_returns.csv* is the raw data\n",
    "\n",
    "The file *fido_returns_funds_on_rows.csv* is the processed data for k-means. Additional details about this file: \n",
    "- Each row represents a mutual fund  \n",
    "- Each column represents a trading day (these are used as features)  \n",
    "- Each value represents the daily percentage change in price between the current trading day and previous trading day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the Data (using pandas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset\n",
    "df0 = pd.read_csv('fido_returns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the head\n",
    "df0.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the tickers in a list called tickers\n",
    "tickers = list(df0.columns[1:])\n",
    "tickers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dates\n",
    "dates = df0.Index.values\n",
    "dates[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the index column\n",
    "del df0['Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataframe values\n",
    "vals = df0.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the data, putting funds on rows and timepoints on columns\n",
    "vals_t = vals.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALUE: 1 POINT\n",
    "# print the shape of the transposed dataframe\n",
    "vals_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataframe w transposed data, calling it dft.\n",
    "dft = pd.DataFrame(data=vals_t, index=df0.columns, columns=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed data to file (in case you wish to work with it later)\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules and Read Data into Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Load data\n",
    "df = spark.read.csv(\"fido_returns_funds_on_rows.csv\", header=True, inferSchema=True)\n",
    "df.select('*').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(VALUE: 2 POINTS) Assemble the Features into a column. \n",
    "Show the first five rows of data ONLY for the features column.\n",
    "(this should make things easier to read)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(VALUE: 2 POINTS) Set up the k-means model and train the model**  \n",
    "Use parameters: \n",
    "- 3 clusters\n",
    "- maximum of 10 iterations \n",
    "- seed=314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(VALUE: 2 POINTS) Compute and Print the Silhouette Score**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(VALUE: 2 POINTS) Define a function `kmeans_range()` that does the following:**\n",
    "- takes an integer representing the lower bound for k\n",
    "- takes an integer representing the upper bound for k\n",
    "- take a Spark DataFrame containing training data\n",
    "- fit K-means with k ranging from lower bound to upper bound, inclusive  \n",
    "- the other parameters should be the same as earlier \n",
    "- for each k, compute the silhouette score\n",
    "- return a pandas dataframe with columns containing k, silhouette score (each row holds the score for given k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans_range() definition here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(VALUE: 1 POINT) Call `kmeans_range` to compute K-means with clusters ranging from 2 to 10 inclusive, printing the resulting dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function call, and printing results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(VALUE: 1 POINTS) Produce a plot with cluster numbers k on the x-axis, sihouette scores on the y-axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
